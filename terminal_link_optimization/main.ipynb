{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av9AyAigIHXG",
        "colab_type": "text"
      },
      "source": [
        "# Terminal Link Optimization\n",
        "\n",
        "This is the main ipython script for the terminal link optimization algorithm.\n",
        "I will update the documentation accordingly once the project has progressed further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUjABdnxIHXM",
        "colab_type": "text"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmpV99xvIHXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NunbIazmIHXW",
        "colab_type": "text"
      },
      "source": [
        "## Make simulation of satellite and customers\n",
        "\n",
        "Lets first start by simulating customers on the ground. This will essentially \n",
        "end up being a straight line with dots (representing customers) being randomly \n",
        "distributed along the line. The line will be spaced according to some \n",
        "arbitrary time metric. Each customer will have (for now) 4 attributes which \n",
        "describe the \"importantness\" of each customer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuYKIBsZIHXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Lets make an array containing the physical location of some simulated customers.\n",
        "The array will have the shape (N_time_segments,length_of_time_segment)\n",
        "\n",
        "customer data array `customer_arr` will be of shape (number of training orbits, number of customers \n",
        "in orbit, number of features describing priority of customers)\n",
        "\"\"\"\n",
        "\n",
        "# training set hyperparameters\n",
        "num_customers = 100 # total number of customers on planet\n",
        "num_orbits = 10000  # total number of training samples (in this case orbits)\n",
        "max_dist = 10000    # maximum distance allowed for customers\n",
        "customer_arr = np.zeros((num_orbits,num_customers,5)) # Define emtpy array to contain customer data\n",
        "\n",
        "for i in range(num_orbits):\n",
        "    # Make customer index labels\n",
        "    customer_arr[i,:,0] = np.arange(start=0,stop=num_customers,step=1)\n",
        "\n",
        "    # Define random locations of customers on a line defining the planet\n",
        "    customer_arr[i,:,1] = np.random.randint(low=0,high=max_dist,size=(num_customers))\n",
        "    \n",
        "    # We will Define 4 variables which describe the `importantness` of each customer\n",
        "\n",
        "    # Assign a random customer important factor. 0 == low importance, 1 == high importance\n",
        "    customer_arr[i,:,2] = np.random.uniform(low=0.0,high=1.0,size=(num_customers))\n",
        "\n",
        "    # Assign a random customer weather factor. 0 == high cloud coverage, 1 == low cloud coverage\n",
        "    customer_arr[i,:,3] = np.random.uniform(low=0.0,high=1.0,size=(num_customers))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeqCYfHIIHXc",
        "colab_type": "text"
      },
      "source": [
        "## Choose optimal order in which to distribute keys (simple approach)\n",
        "\n",
        "This is an incredibly simple algorithm which only takes into account \n",
        "the importantness and weather factors for each customer. It does not \n",
        "take into account the total time customers have been waiting for \n",
        "a key to be distributed to them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHoQra2aIHXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop over all available customers within line-of-sight (this is by default set to num_customers)\n",
        "# This is an example using only one training orbit.\n",
        "for i in range(num_customers):\n",
        "    customer_arr[0,i,4] = customer_arr[0,i,2] * customer_arr[0,i,3]\n",
        "\n",
        "customer_prob_list_idx = np.argsort(customer_arr[0,:,4])[::-1]\n",
        "customer_prob_list = customer_arr[0,customer_prob_list_idx,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHVHRhx-IHXi",
        "colab_type": "code",
        "outputId": "05703e02-a465-40c5-ffea-868074d84770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# Print out ordered list of customers to distribute keys to\n",
        "customer_prob_list"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19., 46.,  0., 30., 45., 95., 74., 32., 76., 65., 53., 43., 78.,\n",
              "       40., 70.,  5.,  3., 21., 84., 73., 97., 81.,  8., 52., 79., 96.,\n",
              "       54., 77., 13., 67., 93.,  1., 31., 49., 92., 99., 24., 50., 35.,\n",
              "       82., 15., 75., 44., 25., 14., 69.,  9., 58., 37., 56., 63., 42.,\n",
              "       86., 28., 27., 90., 72., 48., 71., 26., 57., 55., 20., 51., 39.,\n",
              "       61., 85., 62., 18., 38., 83., 66., 22., 29.,  6., 36., 64.,  4.,\n",
              "       98., 41., 11., 68., 16., 12.,  7., 59., 33., 87., 60., 47.,  2.,\n",
              "       80., 10., 94., 23., 89., 17., 34., 88., 91.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pgpxmkGIHXn",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Approach (complicated approach)\n",
        "\n",
        "I've written some pseudo code down on a piece of paper. Not guranteeing that \n",
        "this will actually work in practice, but I will make my first attempt of this here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXOblSrwIHXo",
        "colab_type": "text"
      },
      "source": [
        "### Define network archetecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPpgkEB0IHXp",
        "colab_type": "code",
        "outputId": "51b2b3d3-057f-4708-d7d0-357d0025b1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# This approach uses the Pytorch neural network library\n",
        "\n",
        "# neural network hyperparameters\n",
        "number_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "# Define network archetecture (convolutional neural network)\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, (1,3), stride=1).double()\n",
        "        self.conv2 = nn.Conv2d(32, 64, (1,3), stride=1).double()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(6144, 120).double()\n",
        "        self.fc2 = nn.Linear(120, 84).double()\n",
        "        self.fc3 = nn.Linear(84, num_customers).double() # one node for predicted probability\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        # Two fully-connected hidden layers and one output layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "print(net)\n",
        "\n",
        "params = list(net.parameters())\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=6144, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=100, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "462PZnjkIHXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(output, target, batch_feature_data):\n",
        "    \"\"\" This is a custom loss function which \n",
        "    takes as input the raw output from the neural \n",
        "    network and returns a loss which attempts to \n",
        "    minimize the number of keys not distributed \n",
        "    within the alloted amount of time.\n",
        "    \"\"\"\n",
        "    \n",
        "    def my_model(output, batch_feature_data):\n",
        "        \"\"\" This is a model which will iterate \n",
        "        over the predicted ordering of keys to be \n",
        "        distributed. There will be a penalty \n",
        "        associated with any keys which are predicted to \n",
        "        be distributed outside of the obersvation window.\n",
        "        \"\"\"\n",
        "\n",
        "        # Assume 5 seconds to distribute key to customer downstream\n",
        "        # Array to store the calculated number of keys lying outside of time alloted\n",
        "        new_output = np.zeros((batch_feature_data.shape[0],1))\n",
        "\n",
        "        # Iterate over all samples in batch\n",
        "        for i in range(batch_feature_data.shape[0]):\n",
        "\n",
        "          # Sort predicted output sample by probability from high to low\n",
        "          tmp_output = np.sort(output[i,:].detach().numpy())[::-1]\n",
        "\n",
        "          # Iterate through probability preds for 1 sample from high to low\n",
        "          dist_cnt = 0              # Initialize distance traveled to be zero\n",
        "          sat_over_horizon = False  # If True, satellite has started going out of reach\n",
        "          for j in range(tmp_output.shape[0]):\n",
        "\n",
        "            # Once satellite goes over horizon, start dropping customers\n",
        "            if dist_cnt >= max_dist:\n",
        "              dist_cnt = 0             # Reset distance counter\n",
        "              sat_over_horizon = True  # set satellite to now be over horizon\n",
        "            \n",
        "            if sat_over_horizon == True:\n",
        "              if batch_feature_data[i,j,0] < dist_cnt:\n",
        "                # Add penalty associated with importantness and weather\n",
        "                new_output[i,0] += (batch_feature_data[i,j,1] + \n",
        "                                    batch_feature_data[i,j,2])\n",
        "\n",
        "            # Add a distance traveled by satellite\n",
        "            dist_cnt += 200\n",
        "    \n",
        "        return torch.tensor(new_output, requires_grad=True)\n",
        "    \n",
        "    # Get number of keys predicted to be outside of target window\n",
        "    pred_model_score = my_model(output, batch_feature_data)\n",
        "\n",
        "    print(pred_model_score.shape,target.shape)\n",
        "    \n",
        "    loss = torch.mean((pred_model_score - torch.tensor(target, requires_grad=True))**2)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efk69hR3IHXv",
        "colab_type": "text"
      },
      "source": [
        "### Run network over entire training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-lTI5MHIHXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training features: location, importance, weather\n",
        "X_train = customer_arr[:,:,1:4]\n",
        "Y_train = np.zeros((num_orbits,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VIwpRiYIHXz",
        "colab_type": "code",
        "outputId": "13d8c293-3315-4f0a-8267-b11df411c852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "running_loss = 0.0\n",
        "train_split = num_orbits\n",
        "\n",
        "dset_train = TensorDataset(torch.tensor(X_train), torch.tensor(Y_train))\n",
        "dataloader = DataLoader(dset_train, batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "# Iterate over entire training set\n",
        "for epoch_num in range(number_epochs):\n",
        "    for i_batch, sampled_batch in enumerate(dataloader):\n",
        "        # in your training loop:\n",
        "        if (train_split - (batch_size * i_batch)) < batch_size:\n",
        "            break\n",
        "        optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output = net(sampled_batch[0].reshape(batch_size,3,1,num_customers).to(device))\n",
        "        loss = custom_loss(output, Y_train[i_batch:i_batch+batch_size].reshape(batch_size,1), sampled_batch[0])\n",
        "        loss.backward()\n",
        "        optimizer.step()    # Does the update to the network    \n",
        "        \n",
        "    \n",
        "    \n",
        "#    print('Training epoch %d/%d' % (epoch_num+1,number_epochs))\n",
        "    # print statistics\n",
        "#    running_loss += loss.item()\n",
        "#    if i % int(X_train.shape[0]/batch_size) == (int(X_train.shape[0]/batch_size) - 1):    # print every 2000 mini-batches\n",
        "#        print('loss: %.3f' %\n",
        "#                (running_loss / 10))\n",
        "#        running_loss = 0.0\n",
        "#        epoch_num += 1\n",
        "#        print('Training epoch %d/%d' % (epoch_num,number_epochs))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n",
            "torch.Size([64, 1]) (64, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-2d5fc8ba9a38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# zero the gradient buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_customers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Does the update to the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-948e28e6919b>\u001b[0m in \u001b[0;36mcustom_loss\u001b[0;34m(output, target, batch_feature_data)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Get number of keys predicted to be outside of target window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mpred_model_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_model_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-948e28e6919b>\u001b[0m in \u001b[0;36mmy_model\u001b[0;34m(output, batch_feature_data)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msat_over_horizon\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m               \u001b[0;32mif\u001b[0m \u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdist_cnt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;31m# Add penalty associated with importantness and weather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 new_output[i,0] += (batch_feature_data[i,j,1] + \n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8lZVHpOIHX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}