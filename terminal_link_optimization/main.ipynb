{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av9AyAigIHXG",
        "colab_type": "text"
      },
      "source": [
        "# Terminal Link Optimization\n",
        "\n",
        "This is the main ipython script for the terminal link optimization algorithm.\n",
        "I will update the documentation accordingly once the project has progressed further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUjABdnxIHXM",
        "colab_type": "text"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmpV99xvIHXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NunbIazmIHXW",
        "colab_type": "text"
      },
      "source": [
        "## Make simulation of satellite and customers\n",
        "\n",
        "Lets first start by simulating customers on the ground. This will essentially \n",
        "end up being a straight line with dots (representing customers) being randomly \n",
        "distributed along the line. The line will be spaced according to some \n",
        "arbitrary time metric. Each customer will have (for now) 4 attributes which \n",
        "describe the \"importantness\" of each customer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuYKIBsZIHXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Lets make an array containing the physical location of some simulated customers.\n",
        "The array will have the shape (N_time_segments,length_of_time_segment)\n",
        "\n",
        "customer data array `customer_arr` will be of shape (number of training orbits, number of customers \n",
        "in orbit, number of features describing priority of customers)\n",
        "\"\"\"\n",
        "\n",
        "# training set hyperparameters\n",
        "num_customers = 100 # total number of customers on planet\n",
        "num_orbits = 10000  # total number of training samples (in this case orbits)\n",
        "max_dist = 10000    # maximum distance allowed for customers\n",
        "dist_step = 200     # distance traveled per step by satellite\n",
        "obs_window = 200    # total size of observation window of satellite in units of distance\n",
        "customer_arr = np.zeros((num_orbits,num_customers,5)) # Define emtpy array to contain customer data\n",
        "\n",
        "# Make training set\n",
        "for i in range(num_orbits):\n",
        "    # Make customer index labels\n",
        "    customer_arr[i,:,0] = np.arange(start=0,stop=num_customers,step=1)\n",
        "\n",
        "    # Define random locations of customers on a line defining the planet\n",
        "    customer_arr[i,:,1] = np.random.randint(low=0,high=max_dist,size=(num_customers))\n",
        "\n",
        "    # Assign a random customer important factor. 0 == low importance, 1 == high importance\n",
        "    customer_arr[i,:,2] = np.random.uniform(low=0.0,high=1.0,size=(num_customers))\n",
        "\n",
        "    # Assign a random customer weather factor. 0 == high cloud coverage, 1 == low cloud coverage\n",
        "    customer_arr[i,:,3] = np.random.uniform(low=0.0,high=1.0,size=(num_customers))\n",
        "\n",
        "# Testing set hyperparameters\n",
        "num_test_orbits = 100 # number of test samples to use\n",
        "customer_test_arr = np.zeros((num_test_orbits,num_customers,5))\n",
        "\n",
        "# Make test set\n",
        "for i in range(num_test_orbits):\n",
        "    # Make customer index labels\n",
        "    customer_test_arr[i,:,0] = np.arange(start=0,stop=num_customers,step=1)\n",
        "\n",
        "    # Define random locations of customers on a line defining the planet\n",
        "    customer_test_arr[i,:,1] = np.random.randint(low=0,high=max_dist,size=(num_customers))\n",
        "\n",
        "    # Assign a random customer important factor. 0 == low importance, 1 == high importance\n",
        "    customer_test_arr[i,:,2] = np.random.uniform(low=0.0,high=1.0,size=(num_customers))\n",
        "\n",
        "    # Assign a random customer weather factor. 0 == high cloud coverage, 1 == low cloud coverage\n",
        "    customer_test_arr[i,:,3] = np.random.uniform(low=0.0,high=1.0,size=(num_customers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeqCYfHIIHXc",
        "colab_type": "text"
      },
      "source": [
        "## Choose optimal order in which to distribute keys (simple approach)\n",
        "\n",
        "This is an incredibly simple algorithm which only takes into account \n",
        "the importantness and weather factors for each customer. It does not \n",
        "take into account the total time customers have been waiting for \n",
        "a key to be distributed to them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHoQra2aIHXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop over all available customers within line-of-sight (this is by default set to num_customers)\n",
        "# This is an example using only one training orbit.\n",
        "for i in range(num_customers):\n",
        "    customer_arr[0,i,4] = customer_arr[0,i,2] * customer_arr[0,i,3]\n",
        "\n",
        "customer_prob_list_idx = np.argsort(customer_arr[0,:,4])[::-1]\n",
        "customer_prob_list = customer_arr[0,customer_prob_list_idx,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHVHRhx-IHXi",
        "colab_type": "code",
        "outputId": "f108d67e-1a35-40c5-f3db-5be93799c18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# Print out ordered list of customers to distribute keys to\n",
        "customer_prob_list"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([86., 19., 54., 62.,  2., 12., 83., 15., 53., 48., 28.,  7., 78.,\n",
              "        0., 31., 16., 35.,  3., 90., 20., 11.,  4., 50., 85., 52., 41.,\n",
              "       51., 57., 74., 68., 40., 33., 43., 95., 26., 34., 46., 60., 89.,\n",
              "       37., 64., 32., 73., 17., 10.,  6., 49.,  8., 84.,  1., 67., 27.,\n",
              "       39., 55., 81., 45., 77., 72., 92., 93., 30., 38., 56., 71., 22.,\n",
              "       94., 47., 18., 29., 99., 44., 82., 88., 87., 69., 61., 24., 58.,\n",
              "       70., 66.,  5., 91., 36., 97., 75., 13., 98., 14., 21.,  9., 23.,\n",
              "       63., 96., 42., 79., 80., 76., 65., 25., 59.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pgpxmkGIHXn",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Approach (complicated approach)\n",
        "\n",
        "I've written some pseudo code down on a piece of paper. Not guranteeing that \n",
        "this will actually work in practice, but I will make my first attempt of this here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXOblSrwIHXo",
        "colab_type": "text"
      },
      "source": [
        "### Define network archetecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPpgkEB0IHXp",
        "colab_type": "code",
        "outputId": "df5d3826-6fb3-4586-ef20-0cb83598b56c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# This approach uses the Pytorch neural network library\n",
        "\n",
        "# neural network hyperparameters\n",
        "number_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "# Define network archetecture (convolutional neural network)\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, (1,3), stride=1).double()\n",
        "        self.conv2 = nn.Conv2d(32, 64, (1,3), stride=1).double()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(6144, 120).double()\n",
        "        self.fc2 = nn.Linear(120, 84).double()\n",
        "        self.fc3 = nn.Linear(84, num_customers).double() # one node for predicted probability\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        # Two fully-connected hidden layers and one output layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "print(net)\n",
        "\n",
        "params = list(net.parameters())\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=6144, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=100, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opdnwSZqoKm-",
        "colab_type": "text"
      },
      "source": [
        "Need to fix loss function, such that it is differentiable. This can be done by \n",
        "scaling the loss calculated for each customer by the predicted probability \n",
        "associated with each customer. We would try to maximize the cost function associated with those who had keys distributed to them, rather than minimize the cost function associated with those who did not get keys distributed to them. See picture on your phone for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "462PZnjkIHXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(output, target, batch_feature_data):\n",
        "    \"\"\" This is a custom loss function which \n",
        "    takes as input the raw output from the neural \n",
        "    network and returns a loss which attempts to \n",
        "    minimize the number of keys not distributed \n",
        "    within the alloted amount of time.\n",
        "    \"\"\"\n",
        "    \n",
        "    def my_model(output, batch_feature_data):\n",
        "        \"\"\" This is a model which will iterate \n",
        "        over the predicted ordering of keys to be \n",
        "        distributed. There will be a penalty \n",
        "        associated with any keys which are predicted to \n",
        "        be distributed outside of the obersvation window.\n",
        "        \"\"\"\n",
        "\n",
        "        # Assume 5 seconds to distribute key to customer downstream\n",
        "        # Array to store the calculated number of keys lying outside of time alloted\n",
        "        new_output = torch.zeros((batch_feature_data.shape[0],num_customers), requires_grad=True)\n",
        "\n",
        "        # Iterate over all samples in batch\n",
        "        for i in range(batch_feature_data.shape[0]):\n",
        "\n",
        "          # Get predicted output for current sample in batch\n",
        "          tmp_output = output[i,:]\n",
        "\n",
        "          dist_cnt = 0\n",
        "          # Satellite travels until maximum distance reached (defined as 1 orbit around Earth)\n",
        "          while dist_cnt <= max_dist:       \n",
        "\n",
        "            num_inside_dist = 0\n",
        "            customers_in_cur_wind_prob = []\n",
        "            customers_in_cur_wind_idx = []\n",
        "            customers_in_cur_wind_feat = []\n",
        "\n",
        "            customers_in_cur_wind = [customer for customer in batch_feature_data[i,:,:] if customer[0] < (dist_cnt + obs_window) and customer[0] > (dist_cnt)]\n",
        "            customers_in_cur_wind_idx = [customer_idx for customer_idx in range(batch_feature_data[i,:,:].shape[0]) if batch_feature_data[i,customer_idx,0] < (dist_cnt + obs_window) and batch_feature_data[i,customer_idx,0] > (dist_cnt)]\n",
        "\n",
        "            \n",
        "            \"\"\"\n",
        "            # Iterate over all customers around the globe\n",
        "            for customer_idx,customer in enumerate(batch_feature_data[i,:,:]):\n",
        " \n",
        "              # If the location of a customer lies within the line-of-sight of satellite \n",
        "              if customer[0] < (dist_cnt + obs_window) and customer[0] > (dist_cnt):\n",
        "                num_inside_dist += 1\n",
        "\n",
        "                # Append predicted probability of key being distributed\n",
        "                customers_in_cur_wind_prob.append(tmp_output[customer_idx])\n",
        "\n",
        "                # Append the index of the customer\n",
        "                customers_in_cur_wind_idx.append(customer_idx)\n",
        "\n",
        "                # Append loss value of customer\n",
        "                customers_in_cur_wind_feat.append(customer[1]*customer[2])\n",
        "            \"\"\"\n",
        "\n",
        "            # If there are no customers within the current line-of-sight, add some small distance traveled to satellite\n",
        "            if not customers_in_cur_wind:\n",
        "              dist_cnt+=dist_step\n",
        "              continue\n",
        "\n",
        "            \n",
        "            \n",
        "            # Of all customers within line-of-sight, choose one with max probability\n",
        "            max_cust = customers_in_cur_wind_idx[torch.argmax(tmp_output[customers_in_cur_wind_idx])]\n",
        "\n",
        "            # Add to batch sample loss max prob customer weather and importantness scaled by predicted probability of key distribution\n",
        "            new_output[i,max_cust] = torch.add(new_output[i,max_cust], (tmp_output[max_cust] * \n",
        "                                                          batch_feature_data[i,max_cust,1] *\n",
        "                                                          batch_feature_data[i,max_cust,2]))\n",
        "            \n",
        "            # Add a distance traveled by satellite (dist_step)\n",
        "            dist_cnt+=dist_step\n",
        "\n",
        "           \n",
        "          #print('Found %d cutomers inside required window of operation' % num_inside_dist)\n",
        "    \n",
        "        return torch.tensor(new_output, requires_grad=True)\n",
        "    \n",
        "    # Get number of keys predicted to be outside of target window\n",
        "    pred_model_score = my_model(output, batch_feature_data)\n",
        "\n",
        "    # Normalize score to be between zero and 1\n",
        "    pred_model_score = torch.div( pred_model_score, torch.max(pred_model_score))\n",
        "    #print(pred_model_score)\n",
        "\n",
        "    # Compute mean squared loss between predictions and target\n",
        "    loss = torch.mean((pred_model_score - torch.tensor(target, requires_grad=True))**2)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efk69hR3IHXv",
        "colab_type": "text"
      },
      "source": [
        "### Run network over entire training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-lTI5MHIHXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training features: location, importance, weather\n",
        "X_train = customer_arr[:,:,1:4]\n",
        "Y_train = np.ones((num_orbits,num_customers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VIwpRiYIHXz",
        "colab_type": "code",
        "outputId": "bd96c580-94bb-435d-f78f-259dc216b482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "source": [
        "running_loss = 0.0\n",
        "train_split = num_orbits\n",
        "\n",
        "dset_train = TensorDataset(torch.tensor(X_train), torch.tensor(Y_train))\n",
        "dataloader = DataLoader(dset_train, batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "# Iterate over entire training set\n",
        "for epoch_num in range(number_epochs):\n",
        "    for i_batch, sampled_batch in enumerate(dataloader):\n",
        "        print(i_batch)\n",
        "        # in your training loop:\n",
        "        if (train_split - (batch_size * i_batch)) < batch_size:\n",
        "            break\n",
        "        optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output = net(sampled_batch[0].reshape(batch_size,3,1,num_customers).to(device))\n",
        "        loss = custom_loss(output, Y_train[i_batch:i_batch+batch_size].reshape(batch_size,num_customers), sampled_batch[0])\n",
        "        loss.backward()\n",
        "        optimizer.step()    # Does the update to the network\n",
        "        #print('Finished a batch')\n",
        "        print('loss: %.3f' %\n",
        "          (loss.item()))    \n",
        "        \n",
        "    \n",
        "    \n",
        "    print('Training epoch %d/%d' % (epoch_num+1,number_epochs))\n",
        "    # print statistics\n",
        "    print('loss: %.3f' %\n",
        "          (loss.item()))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.871\n",
            "1\n",
            "loss: 0.867\n",
            "2\n",
            "loss: 0.873\n",
            "3\n",
            "loss: 0.874\n",
            "4\n",
            "loss: 0.874\n",
            "5\n",
            "loss: 0.873\n",
            "6\n",
            "loss: 0.873\n",
            "7\n",
            "loss: 0.873\n",
            "8\n",
            "loss: 0.872\n",
            "9\n",
            "loss: 0.870\n",
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-4e20e2347361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# zero the gradient buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_customers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_customers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Does the update to the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-ead2a49dcb90>\u001b[0m in \u001b[0;36mcustom_loss\u001b[0;34m(output, target, batch_feature_data)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Get number of keys predicted to be outside of target window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mpred_model_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# Normalize score to be between zero and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-ead2a49dcb90>\u001b[0m in \u001b[0;36mmy_model\u001b[0;34m(output, batch_feature_data)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mcustomers_in_cur_wind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcustomer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcustomer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist_cnt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobs_window\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mcustomers_in_cur_wind_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcustomer_idx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcustomer_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustomer_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist_cnt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobs_window\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustomer_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-ead2a49dcb90>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mcustomers_in_cur_wind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcustomer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcustomer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist_cnt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobs_window\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mcustomers_in_cur_wind_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcustomer_idx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcustomer_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustomer_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist_cnt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobs_window\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_feature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustomer_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5qiS77R8rHV",
        "colab_type": "text"
      },
      "source": [
        "### Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcvZhRuLBt4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    # Get test predictions from trained neural network\n",
        "    test_preds = net(torch.tensor(customer_test_arr[:,:,1:4].reshape(num_test_orbits,3,1,num_customers)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XFrZIumCtXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8lZVHpOIHX2",
        "colab_type": "code",
        "outputId": "06bc51a3-40bd-4b6f-a25f-58fdc25040ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Make scatter plot of priority as a function of key dist probability\n",
        "plt.scatter(test_preds[0,:].detach().numpy(),customer_test_arr[0,:,2])\n",
        "plt.xlabel('Predicted probability of key being distributed')\n",
        "plt.ylabel('Base priority level of customer')\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o2ZfoD-DYxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwgBB0NMd5TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}