{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av9AyAigIHXG",
        "colab_type": "text"
      },
      "source": [
        "# Terminal Link Optimization\n",
        "\n",
        "This is the main ipython script for the terminal link optimization algorithm.\n",
        "I will update the documentation accordingly once the project has progressed further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUjABdnxIHXM",
        "colab_type": "text"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmpV99xvIHXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NunbIazmIHXW",
        "colab_type": "text"
      },
      "source": [
        "## Make simulation of satellite and customers\n",
        "\n",
        "Lets first start by simulating customers on the ground. This will essentially \n",
        "end up being a straight line with dots (representing customers) being randomly \n",
        "distributed along the line. The line will be spaced according to some \n",
        "arbitrary time metric. Each customer will have (for now) 4 attributes which \n",
        "describe the \"importantness\" of each customer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuYKIBsZIHXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Lets make an array containing the physical location of some simulated customers.\n",
        "The array will have the shape (N_time_segments,length_of_time_segment)\n",
        "\n",
        "customer data array `customer_arr` will be of shape (number of training orbits, number of customers \n",
        "in orbit, number of features describing priority of customers)\n",
        "\"\"\"\n",
        "\n",
        "# training set hyperparameters\n",
        "num_customers = 100 # total number of customers on planet\n",
        "num_orbits = 10000  # total number of training samples (in this case orbits)\n",
        "customer_arr = np.zeros((num_orbits,num_customers,5)) # Define emtpy array to contain customer data\n",
        "\n",
        "for i in range(num_orbits):\n",
        "    # Make customer index labels\n",
        "    customer_arr[i,:,0] = np.arange(start=0,stop=num_customers,step=1)\n",
        "\n",
        "    # Define random locations of customers on a line defining the planet\n",
        "    customer_arr[i,:,1] = np.random.randint(low=0,high=10000,size=(num_customers))\n",
        "    \n",
        "    # We will Define 4 variables which describe the `importantness` of each customer\n",
        "\n",
        "    # Assign a random customer important factor. 0 == low importance, 1 == high importance\n",
        "    customer_arr[i,:,2] = np.random.uniform(low=0.0,high=1.0,size=(num_customers))\n",
        "\n",
        "    # Assign a random customer weather factor. 0 == high cloud coverage, 1 == low cloud coverage\n",
        "    customer_arr[i,:,3] = np.random.uniform(low=0.0,high=1.0,size=(num_customers))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeqCYfHIIHXc",
        "colab_type": "text"
      },
      "source": [
        "## Choose optimal order in which to distribute keys (simple approach)\n",
        "\n",
        "This is an incredibly simple algorithm which only takes into account \n",
        "the importantness and weather factors for each customer. It does not \n",
        "take into account the total time customers have been waiting for \n",
        "a key to be distributed to them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHoQra2aIHXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop over all available customers within line-of-sight (this is by default set to num_customers)\n",
        "# This is an example using only one training orbit.\n",
        "for i in range(num_customers):\n",
        "    customer_arr[0,i,4] = customer_arr[0,i,2] * customer_arr[0,i,3]\n",
        "\n",
        "customer_prob_list_idx = np.argsort(customer_arr[0,:,4])[::-1]\n",
        "customer_prob_list = customer_arr[0,customer_prob_list_idx,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHVHRhx-IHXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "87b15491-4836-4f73-9013-61f48893fe90"
      },
      "source": [
        "# Print out ordered list of customers to distribute keys to\n",
        "customer_prob_list"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([53., 11., 49., 79., 98., 66., 87., 59., 77., 44., 84., 28.,  9.,\n",
              "       55., 62., 39., 42., 90., 99., 63., 37., 94., 91., 88., 18., 70.,\n",
              "       65., 45., 76., 67., 52., 68., 57.,  3., 22., 74., 69., 86., 30.,\n",
              "       51., 61., 21., 47., 92., 31., 17., 23., 41.,  7., 71., 20., 35.,\n",
              "       97., 46., 85., 58., 25., 60., 95., 29., 13.,  1.,  8., 72., 10.,\n",
              "       81., 38., 26., 32., 43., 83., 40., 82., 54., 14.,  0., 34., 12.,\n",
              "       75., 89., 36., 48., 96., 56., 64., 19.,  4.,  2., 24., 80.,  6.,\n",
              "       27., 15., 93., 78., 16., 73., 50., 33.,  5.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pgpxmkGIHXn",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Approach (complicated approach)\n",
        "\n",
        "I've written some pseudo code down on a piece of paper. Not guranteeing that \n",
        "this will actually work in practice, but I will make my first attempt of this here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXOblSrwIHXo",
        "colab_type": "text"
      },
      "source": [
        "### Define network archetecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPpgkEB0IHXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "db21f6ea-4e27-416a-b12d-9761d7142a1a"
      },
      "source": [
        "# This approach uses the Pytorch neural network library\n",
        "\n",
        "# neural network hyperparameters\n",
        "number_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "# Define network archetecture (convolutional neural network)\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, (1,3), stride=1).double()\n",
        "        self.conv2 = nn.Conv2d(32, 64, (1,3), stride=1).double()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(6144, 120).double()\n",
        "        self.fc2 = nn.Linear(120, 84).double()\n",
        "        self.fc3 = nn.Linear(84, num_customers).double() # one node for predicted probability\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        # Two fully-connected hidden layers and one output layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "print(net)\n",
        "\n",
        "params = list(net.parameters())\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=6144, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=100, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "462PZnjkIHXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(output, target, batch_feature_data):\n",
        "    \"\"\" This is a custom loss function which \n",
        "    takes as input the raw output from the neural \n",
        "    network and returns a loss which attempts to \n",
        "    minimize the number of keys not distributed \n",
        "    within the alloted amount of time.\n",
        "    \"\"\"\n",
        "    \n",
        "    def my_model(output, batch_feature_data):\n",
        "        \"\"\" This is a model which will iterate \n",
        "        over the predicted ordering of keys to be \n",
        "        distributed. There will be a penalty \n",
        "        associated with any keys which are predicted to \n",
        "        be distributed outside of the obersvation window.\n",
        "        \"\"\"\n",
        "    \n",
        "        return num_pred_outside_window\n",
        "    \n",
        "    # Get number of keys predicted to be outside of target window\n",
        "    num_pred_outside_window = my_model(output, batch_feature_data)\n",
        "    \n",
        "    loss = torch.mean((num_pred_outside_window - target)**2)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efk69hR3IHXv",
        "colab_type": "text"
      },
      "source": [
        "### Run network over entire training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-lTI5MHIHXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training features: location, importance, weather\n",
        "X_train = customer_arr[:,:,1:4]\n",
        "Y_train = np.zeros((num_orbits,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VIwpRiYIHXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a23b4afb-4f4f-4de3-e1a5-900518e8586b"
      },
      "source": [
        "running_loss = 0.0\n",
        "train_split = num_orbits\n",
        "\n",
        "dset_train = TensorDataset(torch.tensor(X_train), torch.tensor(Y_train))\n",
        "dataloader = DataLoader(dset_train, batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "# Iterate over entire training set\n",
        "for epoch_num in range(number_epochs):\n",
        "    for i_batch, sampled_batch in enumerate(dataloader):\n",
        "        \n",
        "        # in your training loop:\n",
        "        if (train_split - (batch_size * i_batch)) < batch_size:\n",
        "            break\n",
        "        optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output = net(sampled_batch[0].reshape(batch_size,3,1,num_customers).to(device))\n",
        "        loss = custom_loss(output, Y_train.reshape(batch_size,1).to(device), sampled_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()    # Does the update\n",
        "        \n",
        "    \n",
        "    \n",
        "#    print('Training epoch %d/%d' % (epoch_num+1,number_epochs))\n",
        "    # print statistics\n",
        "#    running_loss += loss.item()\n",
        "#    if i % int(X_train.shape[0]/batch_size) == (int(X_train.shape[0]/batch_size) - 1):    # print every 2000 mini-batches\n",
        "#        print('loss: %.3f' %\n",
        "#                (running_loss / 10))\n",
        "#        running_loss = 0.0\n",
        "#        epoch_num += 1\n",
        "#        print('Training epoch %d/%d' % (epoch_num,number_epochs))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-c99345781f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# zero the gradient buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_customers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#        loss = custom_loss(output, Y_train.reshape(batch_size,1).to(device), sampled_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-036497fcdaf0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Two fully-connected hidden layers and one output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8lZVHpOIHX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}